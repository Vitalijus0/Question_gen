import streamlit as st
import extra_streamlit_components as stx
import streamlit.components.v1 as components
import torch
from transformers import T5ForConditionalGeneration,T5Tokenizer
from streamlit_tags import st_tags
#import json
#import requests
#import string
#import re
#import nltk
#from nltk.corpus import stopwords
#from nltk.corpus import wordnet
#import traceback
#from nltk.tokenize import sent_tokenize
#from flashtext import KeywordProcessor
#import lt_core_news_lg
#import pke
import spacy
import pandas as pd
import numpy as np
#import spacy_streamlit
#from spacy_streamlit import visualize_ner
#import docx2txt
#import pdfplumber
#import time
#import importlib.util

import base64
from functionforDownloadButtons import download_button
import os
import json
from spacy import displacy

from fill_blanks import tokenize_sentences, get_noun_adj_verb, get_sentences_for_keyword, get_fill_in_the_blanks, text_analysis, fill_blanks_klausimai
from funkcijos import generate_questions, upload_model



st.set_page_config(layout="wide")




@st.cache(allow_output_mutation=True)
def load_model(model_name):
    nlp=spacy.load(model_name)
    return nlp
    
nlp = spacy.load("lt_core_news_lg")
stop_word_list = [line.strip() for line in open("stopwords-lt.txt", 'r')]


trained_model_path = 'model_versions/2021-11-21_5_epoch_squad_sciq/model/'
trained_tokenizer = 'model_versions/2021-11-21_5_epoch_squad_sciq/tokenizer/'


@st.cache(allow_output_mutation=True)
def upload_model(trained_model_path, trained_tokenizer):

    model = T5ForConditionalGeneration.from_pretrained(trained_model_path)
    tokenizer = T5Tokenizer.from_pretrained(trained_tokenizer)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    #print ("device ",device)
    model = model.to(device)

    return model, tokenizer

model, tokenizer = upload_model(trained_model_path, trained_tokenizer)

default_text = """GalilÄ—jas GalilÄ—jus gimÄ— 1564 m. vasario 15 d. Italijoje, Pizos mieste, Äia mokÄ—si, Ä¯stojo Ä¯ universitetÄ…, taÄiau nebaigÄ— jo dÄ—l
finansiniÅ³ sunkumÅ³. VÄ—liau, bÅ«damas 25 metÅ³,[2] pradÄ—jo dÄ—styti matematikÄ… Pizos universitete, Å¡iek tiek
vÄ—liau persikÄ—lÄ— Ä¯ Paduvos universitetÄ…, kur iki 1610 m. dÄ—stÄ— geometrijÄ…, mechanikÄ… ir astronomijÄ…. 1610 m.
apraÅ¡Ä— savo atradimus knygoje â€Å½vaigÅ¾dÅ¾iÅ³ pasiuntinysâ€œ, kuri tapo viena iÅ¡ skaitomiausiÅ³ knygÅ³ Italijoje ir
kitose Å¡alyse.[3] 1612 m. paskelbÄ— darbÄ… â€Svarstymai apie kÅ«nus, kurie yra vandenyje, ir apie tuos, kurie jame
plaukiaâ€œ.[4] 1632 m. iÅ¡leistoje knygoje â€Dialogas apie dvi svarbiausias pasaulio sistemas â€“ Ptolemajo ir
Kopernikoâ€œ pasisakÄ— uÅ¾ Koperniko heliocentrinÄ™ sistemÄ…, tuo uÅ¾sitraukdamas KatalikÅ³ baÅ¾nyÄios nemalonÄ™. UÅ¾
scholastinÄ—s Aristotelio fizikos neigimÄ… 1632 m. jam teko stoti prieÅ¡ inkvizicijos teismÄ…. IÅ¡ pradÅ¾iÅ³
priverstas tylÄ—ti, vÄ—liau, grasinamas kankinimais, atsisakÄ— savo paÅ¾iÅ«rÅ³. Nuo 1633 m. gyveno kaime namÅ³ areÅ¡to
sÄ…lygomis prie Florencijos. 1637 m. apako. Palaidotas Florencijos Santa Croce bazilikoje. 1638 m. Olandijoje
buvo iÅ¡leistas jo veikalas â€Pokalbiai ir matematiniai Ä¯rodinÄ—jimai apie dvi naujas mokslo Å¡akasâ€œ, kuris padÄ—jo
pamatus medÅ¾iagÅ³ mechanikos mokslui."""


context = ''


if "upload_keywords" not in st.session_state:
    st.session_state["upload_keywords"] = "upload"

if "answer_ent" not in st.session_state:
    st.session_state["answer_ent"] = []

# function to get unique values
def unique_values_in_list(list1):
    x = np.array(list1)
    unique_val = np.unique(x).tolist()
    
    return unique_val

def show_pdf(file_path):
    with open(file_path,"rb") as f:
        base64_pdf = base64.b64encode(f.read()).decode('utf-8')
    pdf_display = f'<iframe src="data:application/pdf;base64,{base64_pdf}" width="800" height="800" type="application/pdf"></iframe>'
    st.markdown(pdf_display, unsafe_allow_html=True)

answer_ent = []

def clear_text():
    st.session_state["form_1"] = ""


def main():


    st.title("KlausimÅ³ generavimas")

    

    #with st.form(key='form_1'):

    st.write("form-1")

    with st.expander("See explanation"):
        pdf_file = st.file_uploader("Upload PDFs")
        st.write(type(pdf_file))
        print(type(pdf_file)) 
        if  type(pdf_file) == "streamlit.uploaded_file_manager.UploadedFile":
            st.write(pdf_file.name)
        
    context  = st.text_area("Å iame lange nurodomas tekstas",key='form_1', value=default_text, height=300, max_chars=100000)

    col1, col2, col3 , col4, col5= st.columns(5)

    with col1:
        if st.button("Gauti rekomenduojamus raktaÅ¾odÅ¾ius"):
            st.session_state["answer_ent"] =list(set(get_noun_adj_verb(st.session_state['form_1'])))
    with col2:
        st.button("IÅ¡trinti tekstÄ…", on_click=clear_text)


    with st.form(key='form_2'):
 
        st.write("form-2")
        keywords = st_tags(
            label='Nurodykite raktaÅ¾odÅ¾ius',
            text='Ä®vedÄ™ norimÄ… raktaÅ¾odÄ¯, spauskite Enter',
            value=st.session_state["answer_ent"],
            maxtags = 100)

        

        generate = st.form_submit_button("Sukurti klausimus")

    if generate:
        #context = df3.iloc[-1]['Context']
        if len(keywords) == 0:
            st.warning("BÅ«tina nurodyti bent vienÄ… raktaÅ¾odÄ¯")

        elif len(context) <= 100:
            #print(len(context))
            st.warning("Teksto ilgis turÄ—tu bÅ«ti bent 100 spaudos Å¾enklÅ³")
        else:
            st.session_state["questions"] = generate_questions(model, tokenizer, context, keywords)
        

    if "questions" in st.session_state:

        with st.form(key='form_3'):
            st.write("form-3")
            unique_questions = unique_values_in_list(st.session_state["questions"])


            check_boxes = [st.checkbox(question, key=question) for question in unique_questions]
            checked_questions = [question for question, checked in zip(unique_questions, check_boxes) if checked]
            download_button_submision = st.form_submit_button('Download')
            if download_button_submision:
               download_button(checked_questions, "Data.docx", "ğŸ“¥ Download (.docx)")
            
        @st.cache
        def convert_df(checked_questions):
            df_checked_questions = pd.DataFrame(checked_questions)
            return df_checked_questions.to_csv().encode('utf-8')

        csv = convert_df(checked_questions)

        st.download_button(
            label="Download data as CSV",
            data=csv,
            file_name='large_df.csv',
            mime='text/csv',
            )
        #st.write(type(checked_questions))
        #st.download_button('Download some text', checked_questions)

if __name__ == "__main__":
    main()